{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1732cb38",
   "metadata": {},
   "source": [
    "# VGG16 cats vs dogs\n",
    "\n",
    "# 两个教程的学习 1. 与 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d577c",
   "metadata": {},
   "source": [
    "## 1.学习up小土堆的视频"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db1b30b",
   "metadata": {},
   "source": [
    "##### 1.1 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75d6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313dc8c",
   "metadata": {},
   "source": [
    "##### 1.2 dataset的声明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self,root_dir,label_dir,transform=None):\n",
    "            self.root_dir=root_dir\n",
    "            self.label_dir=label_dir\n",
    "            self.transform = transform\n",
    "            \n",
    "            self.path=os.path.join(self.root_dir,self.label_dir)\n",
    "            self.img_list_path=os.listdir(self.path)\n",
    "            #为了后面 CrossEntropyLoss() 函数期望的 label应该是整数型的张量\n",
    "            self.class_idx = {'cats': 0, 'dogs': 1}  # 类别到索引的映射\n",
    "            \n",
    "\n",
    "    def convert_rgba_to_rgb(self, image):\n",
    "        image_rgb = Image.new(\"RGB\", image.size)\n",
    "        image_rgb.paste(image)\n",
    "        return image_rgb\n",
    "\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "       img_name=self.img_list_path[idx]\n",
    "       self.path = os.path.join(self.root_dir, self.label_dir,img_name)\n",
    "        \n",
    "       image = Image.open(self.path)  #读取这个idx对应的图片\n",
    "       if image.mode != 'RGB':\n",
    "           image = self.convert_rgba_to_rgb(image)  # Convert image to RGB if it's in RGBA format\n",
    "       label=self.label_dir           #并且此图片的标签就是“传”过来的 train文件 下的 子文件名称\n",
    "       label = self.class_idx[label]  # 将标签映射为整数\n",
    "     \n",
    "\n",
    "       \n",
    "       image=self.transform(image)\n",
    "       return  image,label\n",
    "\n",
    "    def __len__(self):\n",
    "       return len(self.img_list_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c134ea",
   "metadata": {},
   "source": [
    "##### 1.3 transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2553242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # 假设使用224x224大小的图片输入\n",
    "    transforms.ToTensor(),           # 将图片转换为张量\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8f706",
   "metadata": {},
   "source": [
    "##### 1.4 dataset 的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_train = \"dataset/training_set\"\n",
    "root_dir_test = \"dataset/test_set\"\n",
    "\n",
    "cats_dataset=MyData(root_dir_train,\"cats\",transform=transform)\n",
    "dogs_dataset=MyData(root_dir_train,\"dogs\",transform=transform)\n",
    "cats_test_dataset = MyData(root_dir_test, \"cats\", transform=transform)\n",
    "dogs_test_dataset = MyData(root_dir_test, \"dogs\", transform=transform)\n",
    "print(f\"猫训练数据集有{len(cats_dataset)}张，猫测试数据集有{len(cats_test_dataset)}张\")\n",
    "print(f\"狗训练数据集有{len(dogs_dataset)}张，狗测试数据集有{len(dogs_test_dataset)}张\")\n",
    "\n",
    "# 训练数据集\n",
    "train_dataset= cats_dataset + dogs_dataset\n",
    "\n",
    "# 测试数据集\n",
    "total_test_dataset = cats_test_dataset + dogs_test_dataset\n",
    "\n",
    "print(f\"训练数据集有{len(train_dataset)}张，测试数据集有{len(total_test_dataset)}张\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b894b4",
   "metadata": {},
   "source": [
    "##### 1.5 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012583d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=0)\n",
    "\n",
    "total_test_dataloader=DataLoader(total_test_dataset,batch_size=batch_size,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0c0e3",
   "metadata": {},
   "source": [
    "##### 1.6 device (GPU能加速 1网络模型、2损失函数、3数据集的图和label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1831a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"使用的设备{}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61703d29",
   "metadata": {},
   "source": [
    "##### 1.7.1  net (下面这个NET1() 类是跟着视频敲的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742528b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NET1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 第一个卷积块\n",
    "        self.conv1=nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.relu1=nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2=nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 第二个卷积块\n",
    "        self.conv3=nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv4=nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 第三个卷积块\n",
    "        self.conv5=nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv6=nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv7=nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 第四个卷积块\n",
    "        self.conv8=nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.relu8 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv9=nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.relu9 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv10=nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.relu10 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 第五个卷积块\n",
    "        self.conv11=nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.relu11 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv12=nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.relu12 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv13=nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.relu13 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool5=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # flatten(x, 1)\n",
    "        self.flatten=nn.Flatten()\n",
    "\n",
    "    #三个全连接层\n",
    "        self.linear1=nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.relu14 = nn.ReLU(inplace=True)\n",
    "        self.dropout=nn.Dropout()\n",
    "\n",
    "        self.linear2=nn.Linear(4096, 4096)\n",
    "        self.relu15 = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "        self.linear3=nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "       x = self.conv1(x)\n",
    "       x = self.relu1(x)\n",
    "       x = self.conv2(x)\n",
    "       x = self.relu2(x)\n",
    "       x = self.pool1(x)\n",
    "\n",
    "       x = self.conv3(x)\n",
    "       x = self.relu3(x)\n",
    "       x = self.conv4(x)\n",
    "       x = self.relu4(x)\n",
    "       x = self.pool2(x)\n",
    "\n",
    "       x = self.conv5(x)\n",
    "       x = self.relu5(x)\n",
    "       x = self.conv6(x)\n",
    "       x = self.relu6(x)\n",
    "       x = self.conv7(x)\n",
    "       x = self.relu7(x)\n",
    "       x = self.pool3(x)\n",
    "\n",
    "       x = self.conv8(x)\n",
    "       x = self.relu8(x)\n",
    "       x = self.conv9(x)\n",
    "       x = self.relu9(x)\n",
    "       x = self.conv10(x)\n",
    "       x = self.relu10(x)\n",
    "       x = self.pool4(x)\n",
    "\n",
    "       x = self.conv11(x)\n",
    "       x = self.relu11(x)\n",
    "       x = self.conv12(x)\n",
    "       x = self.relu12(x)\n",
    "       x = self.conv13(x)\n",
    "       x = self.relu13(x)\n",
    "       x =  self.pool5(x)\n",
    "       #\n",
    "       x = self.flatten(x)\n",
    "       #\n",
    "       x = self.linear1(x)\n",
    "       x = self.relu14(x)\n",
    "       x = self.dropout()\n",
    "\n",
    "       x = self.linear2(x)\n",
    "       x = self.relu15(x)\n",
    "       x = self.dropout()\n",
    "\n",
    "       x = self.linear3(x)\n",
    "\n",
    "\n",
    "       return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268434b",
   "metadata": {},
   "source": [
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "### Parameters:\n",
    " in_channels (int) – Number of channels in the input image\n",
    "\n",
    " out_channels (int) – Number of channels produced by the convolution\n",
    "\n",
    " kernel_size (int or tuple) – Size of the convolving kernel\n",
    "\n",
    "stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "\n",
    " padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0\n",
    "\n",
    "padding_mode (str, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'\n",
    "\n",
    "dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1\n",
    "\n",
    "groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1\n",
    "\n",
    "bias (bool, optional) – If True, adds a learnable bias to the output. Default: True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597c877",
   "metadata": {},
   "source": [
    "##### 1.7.2  下面的NET2类使用了nn.Sequential( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NET2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # 第一个卷积块\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),  # CON1 in_channel=3,out_channel=64  (3,224,224)->(64,224,224)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), #CON2 in_channel=64,out_channel=64 (64,224,224)->(64,224,224)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Pool_1  (64,  [224,224])->(64,  [112,112])\n",
    "\n",
    "            # 第二个卷积块\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),   #CON3 out_channel=128  (64,112,112)->( [128],112,112)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),   #CON4 out_channel=128  (128,112,112)->( 128 ,112,112)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Pool_2  (128,   [112,112])->(128,   [56,56])\n",
    "\n",
    "            # 第三个卷积块\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), #CON5 out_channel=256  (128,56,56)->( [256] ,56,56)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), #CON6 (256,56,56)->(256,56,56)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), #CON7 (256,56,56)->(256,56,56)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Pool_3  (256, [56,56])->(256, [28,28])\n",
    "\n",
    "            # 第四个卷积块\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1), #CON8 (256,28,28)->( 512 ,28,28)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), #CON9 (512,28,28)->( 512 ,28,28)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), #CON10 (512,28,28)->( 512 ,28,28)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),      # Pool_4  (512, [28,28])->(512, [14,14])\n",
    "\n",
    "            # 第五个卷积块\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), #CON11 (512,14,14)->( 512 ,14,14)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), #CON12 (512,14,14)->( 512 ,14,14)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), #CON13 (512,14,14)->( 512 ,14,14)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),     # Pool_5  (512, [14,14])->(512, [7,7])\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "         ########################   然后执行   flatten(x, 1)\n",
    "\n",
    "        # 定义VGG16的全连接部分，包括三个全连接层\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),  # 512 * 7 * 7 -> 4096*1*1\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),         # 4096*1*1 -> 4096*1*1\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1000),   # 4096*1*1 -> 2*1*1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)  #############  flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    in_data=torch.ones(1,3,224,224)\n",
    "    net = NET2()\n",
    "    net.load_state_dict(torch.load(r\"vgg16-397923af.pth\"))\n",
    "    net.classifier.add_module(\"my\",nn.Linear(1000,2))\n",
    "    print(net)\n",
    "    out= net (in_data)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997ea3a",
   "metadata": {},
   "source": [
    "##### 1.8 把net放到device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4986000",
   "metadata": {},
   "source": [
    "##### 1.9损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss=CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059df25",
   "metadata": {},
   "source": [
    "##### 1.10 损失函数放到device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae2e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8329f",
   "metadata": {},
   "source": [
    "##### 1.11优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75231d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate= 1e-4\n",
    "\n",
    "# opt=torch.optim.Adam(net.parameters(),lr=learn_rate)\n",
    "optim=torch.optim.SGD(net.parameters(),lr=learn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fa3977",
   "metadata": {},
   "source": [
    "##### 1.12训练过程和验证过程 框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9aff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_losses = []\n",
    "list_test_losses = []\n",
    "\n",
    "# train\n",
    "for i in range(2):\n",
    "          print(\"-------第 {} 轮训练开始-------\".format(i+1))\n",
    "          start_time=time.time()\n",
    "\n",
    "          loss_in_one_epoch=0.0\n",
    "          accuracy_sum=0.0\n",
    "\n",
    "          for data in train_dataloader:\n",
    "              images, labels = data\n",
    "              images = images.to(device)\n",
    "              labels = labels.to(device)\n",
    "\n",
    "              optim.zero_grad()  # 每次都不被上一次的权重影响\n",
    "\n",
    "              outputs = net(images)\n",
    "              loss_out = loss(outputs, labels)\n",
    "\n",
    "              loss_out.backward()\n",
    "              optim.step()  #调优\n",
    "\n",
    "              loss_in_one_epoch += loss_out\n",
    "              list_train_losses.append(loss_out)\n",
    "              accuracy = (outputs.argmax(1) == labels).sum()\n",
    "              accuracy_sum += accuracy\n",
    "          end_time=time.time()\n",
    "          print(\"第{}轮训练结束,用时{},总的loss为{}\".format(i + 1,end_time-start_time,loss_in_one_epoch))\n",
    "          print(\"这次的正确率: {}\".format(accuracy_sum/len(train_dataset)))\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "          # 测试\n",
    "          sum_loss = 0.0\n",
    "          accuracy_sum = 0.0\n",
    "          for images, labels in total_test_dataloader:\n",
    "              with torch.no_grad():\n",
    "                  images = images.to(device)\n",
    "                  labels = labels.to(device)\n",
    "\n",
    "                  optim.zero_grad()  ########################新增 梯度清零\n",
    "                  outputs = net(images)\n",
    "\n",
    "                  accuracy = (outputs.argmax(1) == labels).sum()\n",
    "                  accuracy_sum += accuracy\n",
    "                  loss_1 = loss(outputs, labels)\n",
    "                  sum_loss += loss_1\n",
    "                  list_test_losses.append(loss_1)\n",
    "          print(\"这一次测试的loss是{}\".format(sum_loss))\n",
    "          print(\"此次测试的正确率: {}\".format(accuracy_sum / len(total_test_dataset)))\n",
    "\n",
    "\n",
    "          torch.save(net, \"net_{}.pth\".format(i+1))\n",
    "          print(\"模型已保存\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64f0ea",
   "metadata": {},
   "source": [
    "##### 1.13测试过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(output_image_path)\n",
    "test = transform(image)\n",
    "test = torch.reshape(test, (1, 3, 224, 224))\n",
    "test = test.to('cuda')\n",
    "\n",
    "\n",
    "model = torch.load(r\"net_2.pth\")\n",
    "output = model(test)\n",
    "\n",
    "a=int(output.argmax(1))\n",
    "\n",
    "if a == 1:  # 标签的数字索引1对应dog\n",
    "  print(\"dog\")\n",
    "else:\n",
    "  print(\"cat\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337fc78",
   "metadata": {},
   "source": [
    "# 2. 学习别人的VGG16 CATS vs DOGS,然后升级自己的成为4分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262fb53",
   "metadata": {},
   "source": [
    "#### 与我上面所学习的不同之处是：\n",
    "####                                                   .1数据集的处理，\n",
    "####                                                   .2VGG网络的构建方式\n",
    "####                                                   .3测试的交互界面更好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62107191",
   "metadata": {},
   "source": [
    "##### 2.1 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e135ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from numpy import random\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494a3a1",
   "metadata": {},
   "source": [
    "##### 2.2生成一个.txt（.txt的每行 是 图片地址 和 这张图片的label ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "animal_class= ['cat','dog','bee','ant']  # \"train\" 有新增了 bee , ant\n",
    "root_dir=r\"train\"\n",
    "\n",
    "if __name__=='__main__':\n",
    "    f=open(\"data.txt\",mode=\"w\")\n",
    "    items = os.listdir(root_dir) #返回一个包含此目录中所有子目录名称的列表list\n",
    "    for item in items:           #for循环去访问list中的每个元素\n",
    "\n",
    "        if item not in animal_class:\n",
    "            continue\n",
    "\n",
    "        # label\n",
    "        label=animal_class.index(item)\n",
    "        #图片名字\n",
    "        pic_path = os.path.join(root_dir,item)\n",
    "        pic_name_list=os.listdir(pic_path) #返回一个包含此目录下所有图片名称的列表\n",
    "        # 写入txt\n",
    "        for every_pic_name in pic_name_list:\n",
    "           f.write(str(label)+\";\"+\"%s%s%s\" % (pic_path,'/',every_pic_name))\n",
    "           f.write(\"\\n\")\n",
    "\n",
    "    f.close()\n",
    "\n",
    "# 很关键的os.listdir（）函数，能够或得你输入的path下面所有文件的名字的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88ec8c",
   "metadata": {},
   "source": [
    "##### 2.3定义mydataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ae7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydataset(Dataset):\n",
    "    \"\"\"\n",
    "    这是一个继承了Dataset类的子类，\n",
    "    需要去传入你的包含有图片名称的list以及transform，\n",
    "    list可以是通过切片的一段sub_list，这样可以有不同的sub_list对应train_dataset和 test_dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,sub_list,transform=None):\n",
    "        self.sub_list=sub_list\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sub_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #标签\n",
    "        label=int(self.sub_list[index].split(\";\")[0])\n",
    "\n",
    "        #图片\n",
    "        image_path=self.sub_list[index].split(\";\")[1].strip('\\n')\n",
    "        image=Image.open(image_path)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "            image.save(image_path)\n",
    "\n",
    "        #transform\n",
    "        image=self.transform(image)\n",
    "\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c12739",
   "metadata": {},
   "source": [
    "##### 2.4 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开txt.py得到的“data.txt”,用readlines方法得到一个list\n",
    "with open(\"data.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "\n",
    "# 打乱lines的顺序,为数据集做准备\n",
    "random.shuffle(lines)\n",
    "\n",
    "val_number = int(len(lines) * 0.2)\n",
    "train_number = len(lines) - val_number\n",
    "\n",
    "\n",
    "# transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 假设使用224x224大小的图片输入\n",
    "    transforms.ToTensor(),  # 将图片转换为张量\n",
    "])\n",
    "\n",
    "# dataset\n",
    "val_dataset = mydataset(lines[:val_number], transform=transform)\n",
    "train_dataset = mydataset(lines[val_number:], transform=transform)\n",
    "print(f\"train集长度{len(train_dataset)},val集的长度{len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8187c49",
   "metadata": {},
   "source": [
    "##### 2.5 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 注意 \"D\"和\"L\"都是大写\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb160c",
   "metadata": {},
   "source": [
    "##### 2.6device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9897b",
   "metadata": {},
   "source": [
    "##### 2.7.1 net VGG16  \n",
    "*从pytorch 官网的VGG16源码里面来的，其实也可以自己去构建*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    \"vgg16\": \"https://download.pytorch.org/models/vgg16-397923af.pth\",\n",
    "\n",
    "}#权重下载网址\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_classes = 1000, init_weights= True, dropout = 0.5):\n",
    "        super(VGG,self).__init__()\n",
    "        self.features = features   # features参数表示卷积层的结构 ？？？\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))#AdaptiveAvgPool2d使处于不同大小的图片也能进行分类\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),#完成4096的全连接\n",
    "            nn.Linear(4096, num_classes),#对num_classes的分类\n",
    "        )\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, 0, 0.01)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  #卷积\n",
    "        x = self.avgpool(x)   #池化\n",
    "        x = torch.flatten(x, 1)#对输入层进行平铺，转化为一维数据\n",
    "        x = self.classifier(x) #全连接\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm = False):#make_layers对输入的cfg进行循环\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:#对cfg进行输入循环,取第一个v\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]#把输入图像进行缩小\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)#输入通道是3，输出通道64\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "\n",
    "}\n",
    "\n",
    "def vgg16(pretrained=False, progress=True,num_classes=2):\n",
    "    model = VGG(make_layers(cfgs['D']))\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['vgg16'],model_dir='./model' ,progress=progress)#预训练模型地址\n",
    "        model.load_state_dict(state_dict)\n",
    "    if num_classes !=1000:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),#随机删除一部分不合格\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),#防止过拟合\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    in_data=torch.ones(1,3,224,224)\n",
    "    net=vgg16(pretrained=True, progress=True,num_classes=2)\n",
    "    print(net)\n",
    "    out=net(in_data)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b33df",
   "metadata": {},
   "source": [
    "##### 2.7.2 自己去构建NET类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e34eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),  # 参数inplace = True是指原地进行操作，操作完成后覆盖原来的变量\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 224*224 变成了 112*112\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),  # 参数inplace = True是指原地进行操作，操作完成后覆盖原来的变量\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 112*112变成56*56\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),  # 参数inplace = True是指原地进行操作，操作完成后覆盖原来的变量\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 56*56变成 28*28\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 28*28 变成 14*14\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 14*14 变成 7*7\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),  # 512 * 7 * 7 -> 4096*1*1\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),  # 防止过拟合\n",
    "\n",
    "            nn.Linear(4096, 4096),  # 4096*1*1 -> 4096*1*1\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),  # 防止过拟合\n",
    "\n",
    "            nn.Linear(4096, 1000),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549e520",
   "metadata": {},
   "source": [
    "##### 2.7.3 加载2.7.2的NET类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d191345",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=NET()\n",
    "net.load_state_dict(torch.load(r\"vgg16-397923af.pth\"))\n",
    "net.classifier.add_module(\"my\",nn.Linear(1000,4)) # 注意我这里最后是4，因为4分类。\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0275872",
   "metadata": {},
   "source": [
    "##### 2.8 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfad970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt优化器\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532dc905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "my_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13743064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN & VAL\n",
    "epochs = int(input('输入轮数：'))\n",
    "\n",
    "list_train_losses = []\n",
    "list_test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_losses = 0.0\n",
    "    test_losses = 0.0\n",
    "    total_accuracy = 0.0\n",
    "\n",
    "    for data in train_dataloader:\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        output = net(image)\n",
    "\n",
    "        train_loss = my_loss(output, label)\n",
    "        train_loss.backward()\n",
    "        optim.step()  # 优化器更新\n",
    "        train_losses += train_loss\n",
    "\n",
    "    list_train_losses.append(train_losses / len(train_dataset))  # 平均损失相加\n",
    "    # 测试\n",
    "    for data in val_dataloader:\n",
    "        image, label = data\n",
    "        with torch.no_grad():\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            out = net(image)  # 投入网络\n",
    "\n",
    "            test_loss = my_loss(out, label)\n",
    "            test_losses += test_loss\n",
    "\n",
    "            accuracy = (out.argmax(1) == label).sum()  #####\n",
    "            # accuracy = ((out.argmax(1) == label).sum()).clone().detach().cpu().numpy()  # 正确预测的总和比测试集的长度，即预测正确的精度\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "    list_test_losses.append(test_losses / len(val_dataset))\n",
    "\n",
    "    print(\"第{}轮\".format(epoch + 1))\n",
    "    print(\"训练集损失：{}\".format(train_losses))\n",
    "    print(\"验证集损失：{}\".format(test_losses))\n",
    "    print(\"验证集上的精度：{:.1%}\".format(total_accuracy / len(val_dataset)))\n",
    "\n",
    "    # torch.save(net,\"4_classes_{}.pth\".format(epoch+1))\n",
    "    # print(\"模型已保存\")\n",
    "\n",
    "# list_train_losses = [item.item() for item in list_train_losses]\n",
    "# list_test_losses = [item.item() for item in list_test_losses]\n",
    "#\n",
    "# plt.plot(list(range(1, len(list_train_losses) + 1)), list_train_losses, color='blue', marker='o', label='train_loss')\n",
    "# plt.plot(list(range(1, len(list_test_losses) + 1)), list_test_losses, color='red', marker='o', label='test_loss')\n",
    "#\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.savefig(r\"plot.png\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070ec8e",
   "metadata": {},
   "source": [
    "##### 2.9 test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baec373",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 假设使用224x224大小的图片输入\n",
    "    transforms.ToTensor(),  # 将图片转换为张量\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "image_path=r\"test.png\"\n",
    "\n",
    "i=Image.open(image_path)\n",
    "if i.mode != 'RGB':\n",
    "    i = i.convert('RGB')\n",
    "    i.save(image_path)\n",
    "\n",
    "img=Image.open(image_path)\n",
    "image=transform(img)\n",
    "image = torch.reshape(image, (1, 3, 224, 224))\n",
    "\n",
    "model=torch.load(r\"4_classes_1.pth\")\n",
    "image=image.to('cuda')\n",
    "\n",
    "\n",
    "out = model(image)\n",
    "\n",
    "print(\"从模型出来的out\",out)\n",
    "out=torch.nn.functional.softmax(out,dim=1)\n",
    "print(\"经过softmax的out\",out)\n",
    "\n",
    "a=int(out.argmax(1))\n",
    "\n",
    "out=out.data.cpu().numpy()\n",
    "# animal_class=['cat','dog','bee','ant']\n",
    "plt.suptitle(\"Classes:{},P={:.1%}\".format(animal_class[a],out[0,a]))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
